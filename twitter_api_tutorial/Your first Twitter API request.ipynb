{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395daaf6",
   "metadata": {},
   "source": [
    "*Hello and welcome!* ðŸ‘‹\n",
    "\n",
    "This notebook is the <u>first</u> part of a **tutorial** on how to **get started with Twitter API v2 using Python** ðŸ¤“! Read our medium blog post [here](https://medium.com/data-analytics-at-nesta).\n",
    "\n",
    "In this notebook, we start by making a very simple request to the **recent search** endpoint, using heat pump mentions on Twitter as our use case.\n",
    "\n",
    "**More on the use case**\n",
    "\n",
    "The [sustainable future mission](https://www.nesta.org.uk/sustainable-future/) at [Nesta](https://www.nesta.org.uk/) is focused on projects to help decarbonise UK homes, with special interest in greener heating systems such as heat pumps. For those who are not familiar with the concept, a heat pump is a low-carbon heating system that captures heat from outside and moves it into your home.\n",
    "\n",
    "Let us have a go at collecting tweets mentioning heat pumps!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e44eb4",
   "metadata": {},
   "source": [
    "### Importing packages and loading credentials\n",
    "We start by importing the necessary packages to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d638597b",
   "metadata": {},
   "source": [
    "We import our *bearer_token* which we previously defined as an environment variable. This way you do not have to expose your credentials in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fbb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = os.environ.get(\"BEARER_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c239cd51",
   "metadata": {},
   "source": [
    "### Preparing our API request\n",
    "We will use the recent search endpoint to collect our first set of tweets. To do that we need to define the endpoint URL, the rules clarifying the data we want to collect and other query parameters (such as fields to include and maximum number of results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3275464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = \"https://api.twitter.com/2/tweets/search/recent\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740d1ad5",
   "metadata": {},
   "source": [
    "We create a dictionary with query parameters, where we pass the following fields:\n",
    "- **query**: with the rule to query the data. In this case we will collect tweets matching on one of the expressions \"heat pump\"/\"heat pumps\", written in english, which are not retweets.\n",
    "- **tweet.fields**: fields in the tweet object for which we want to collect information, in this example: the tweet unique identifier, the tweet text, the identifier of the user posting the tweet and the date/time the tweet was created;\n",
    "- **max_results**: the maximum number of tweets to be retrieved per request to the API (defaults to 10 with a maximum of 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dceb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_parameters = {\n",
    "    \"query\": '(\"heat pump\" OR \"heat pumps\") lang:en -is:retweet',\n",
    "    \"tweet.fields\": \"id,text,author_id,created_at\",\n",
    "    \"max_results\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb999b47",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "Authentication is done by bearer token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8e1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_headers(bearer_token: str) -> dict:\n",
    "    \"\"\"\n",
    "    Sets up the request headers. \n",
    "    Returns a dictionary summarising the bearer token authentication details.\n",
    "    \"\"\"\n",
    "    return {\"Authorization\": \"Bearer {}\".format(bearer_token)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d335182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = request_headers(bearer_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5de79d",
   "metadata": {},
   "source": [
    "### Connecting to endpoint and requesting data\n",
    "We connect to the endpoint and retrieve our first page of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a779cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_endpoint(endpoint_url: str, headers: dict, parameters: dict) -> json:\n",
    "    \"\"\"\n",
    "    Connects to the endpoint and requests data.\n",
    "    Returns a json with Twitter data if a 200 status code is yielded.\n",
    "    Programme stops if there is a problem with the request and sleeps\n",
    "    if there is a temporary problem accessing the endpoint.\n",
    "    \"\"\"\n",
    "    response = requests.request(\n",
    "        \"GET\", url=endpoint_url, headers=headers, params=parameters\n",
    "    )\n",
    "    response_status_code = response.status_code\n",
    "    if response_status_code != 200:\n",
    "        if response_status_code >= 400 and response_status_code < 500:\n",
    "            raise Exception(\n",
    "                \"Cannot get data, the program will stop!\\nHTTP {}: {}\".format(\n",
    "                    response_status_code, response.text\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        sleep_seconds = random.randint(5, 60)\n",
    "        print(\n",
    "            \"Cannot get data, your program will sleep for {} seconds...\\nHTTP {}: {}\".format(\n",
    "                sleep_seconds, response_status_code, response.text\n",
    "            )\n",
    "        )\n",
    "        time.sleep(sleep_seconds)\n",
    "        return connect_to_endpoint(endpoint_url, headers, parameters)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = connect_to_endpoint(endpoint_url, headers, query_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e0ed4",
   "metadata": {},
   "source": [
    "### Taking a look at the collected data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a397e420",
   "metadata": {},
   "source": [
    "The **json_response** variable contains our Twitter data. It is a dictionary with two keys, *data* and *meta* (standing for metadata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941279e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ba9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e238e",
   "metadata": {},
   "source": [
    "If we take a look at *meta*, we can see that it contains information about the newest and oldest tweet identifiers collected, the number of tweets collected and a *next_token* identifier. We will learn more about the *next_token* identifier in the next notebook of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d9be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response[\"meta\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e91feb",
   "metadata": {},
   "source": [
    "And now, let's finally take a look at the tweets!\n",
    "\n",
    "json_response[\"data\"] is a list of dictionaries with size equal to the *result_count* query parameter (i.e. number of tweets we collected, in this case 10). Each dictionary in the list represents one tweet and it contains the **tweet.fields** information for each tweet.\n",
    "\n",
    "With this first request we get the newest possible tweets matching our rule in the past 7 days - but not all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(json_response[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56196497",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response[\"data\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47963601",
   "metadata": {},
   "source": [
    "**Here we are! We have collected our first 10 tweets** ðŸ’ªðŸ¤“\n",
    "\n",
    "In the next notebook, **\"Tweets from the past 7 days\"**, we will build on this code and use the recent search endpoint to its full potential to retrieve the remaining tweets from the last 7 days.\n",
    "\n",
    "This code was inspired in official Twitter code in this [GitHub repo](https://github.com/twitterdev/Twitter-API-v2-sample-code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce25260b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('exploration_recc_complaints')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4fe1efbf936c83866a89d8e9c252ce8658e499fc60c55263e5ba75244106e72f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
